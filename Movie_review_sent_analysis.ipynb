{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using RNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dFYOFyWrgl3m"
   },
   "outputs": [],
   "source": [
    "# Importing all the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation \n",
    "from collections import Counter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jmfi7ZQ4gmeT",
    "outputId": "f2f1ecda-54f8-48ca-cded-31f66cd3ad43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ\n",
      "\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "posi\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "with open('review.txt', 'r', encoding='utf-8') as f:\n",
    "    reviews = f.read()\n",
    "with open('sentiment.txt', 'r', encoding='utf-8') as f:\n",
    "    labels = f.read()\n",
    "\n",
    "print(reviews[:500])\n",
    "print()\n",
    "print(labels[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAipWS7BWSiz"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DqOqbUIbgmqa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'youll',\n",
       " 'be',\n",
       " 'hooked',\n",
       " 'they',\n",
       " 'are',\n",
       " 'right',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'exactly',\n",
       " 'what']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing all the punctuation and converting to lower case\n",
    "reviews = reviews.lower() \n",
    "alltext = ''.join([c for c in reviews if c not in punctuation])\n",
    "\n",
    "# Splitting by new lines and spaces\n",
    "r_split = alltext.split('\\n')\n",
    "alltext = ' '.join(r_split)\n",
    "\n",
    "# Create a list of words\n",
    "words = alltext.split()\n",
    "words[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-psDXfTJXazm"
   },
   "source": [
    "## Encoding the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q17OTCHQgmoP"
   },
   "outputs": [],
   "source": [
    "## Build a dictionary that maps words to integers \n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vk1q_eaBE1fB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  182727\n",
      "Tokenized review: \n",
      " [[28, 4, 1, 77, 1941, 44, 1063, 11, 100, 145, 40, 479, 3324, 393, 461, 26, 3190, 34, 23, 205, 14, 10, 6, 601, 48, 590, 15, 2136, 12, 1, 87, 146, 11, 3255, 69, 42, 3324, 13, 29, 5600, 2, 15378, 134, 4, 582, 61, 282, 7, 205, 35, 1, 670, 138, 1707, 69, 10, 6, 21, 3, 118, 16, 1, 8330, 5794, 39, 11861, 10, 118, 2507, 55, 6063, 15, 5636, 5, 1469, 381, 39, 582, 29, 6, 3407, 7, 1, 352, 339, 4, 1, 23503, 12, 8, 6, 469, 3324, 14, 11, 6, 1, 11516, 338, 5, 1, 16020, 6870, 2543, 1061, 61700, 8, 2636, 1375, 20, 25362, 536, 33, 4727, 2520, 4, 1, 1208, 112, 31, 1, 7152, 25, 2992, 13017, 2, 408, 61701, 37, 17526, 6, 21, 319, 20, 1, 5097, 3745, 536, 6, 344, 5, 81870, 8469, 41125, 15379, 5170, 7893, 2461, 2, 18403, 61702, 329, 9263, 7467, 13444, 2, 8720, 34937, 23, 109, 224, 5435, 12, 9, 57, 128, 1, 269, 1303, 4, 1, 118, 6, 668, 5, 1, 187, 11, 8, 262, 112, 77, 257, 548, 2999, 819, 178, 1271, 4349, 16, 2499, 1095, 819, 1412, 819, 81871, 147, 978, 181, 1, 87, 393, 9, 120, 201, 3255, 69, 14, 37, 1574, 8, 13, 2214, 9, 397, 128, 9, 13, 1549, 16, 8, 18, 14, 9, 278, 51, 9, 1462, 3, 1250, 16, 3324, 2, 183, 10277, 5, 1, 319, 2091, 4, 2099, 582, 21, 40, 582, 18, 7964, 7153, 4972, 14177, 26, 2969, 45, 16, 3, 32613, 7036, 14177, 494, 20, 620, 2, 75, 240, 15, 8, 73, 9935, 753, 816, 7036, 106, 660, 81, 1208, 20587, 668, 5, 63, 549, 4, 931, 1996, 39, 1208, 557, 145, 3324, 22, 196, 411, 3778, 15, 48, 6, 3274, 81872, 43, 22, 68, 75, 7, 1211, 15, 122, 4018, 501]]\n"
     ]
    }
   ],
   "source": [
    "reviews_int = [] \n",
    "for review in r_split:     \n",
    "  reviews_int.append([vocab_to_int[word] for word in review.split()])\n",
    "\n",
    "# Test the encoding\n",
    "# stats about vocabulary\n",
    "print('Unique words: ', len((vocab_to_int)))\n",
    "\n",
    "# Print tokens in first review \n",
    "print('Tokenized review: \\n', reviews_int[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJDadORTE1kO",
    "outputId": "26b53d3d-e535-4cda-db87-a615748e8c65"
   },
   "outputs": [],
   "source": [
    "# 1=positive, 0=negative \n",
    "l_split = labels.split('\\n') \n",
    "encoded_labels = np.array([1 if label == 'positive' else 0 for label in l_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sssHmB1cE1m1",
    "outputId": "1f2f9ed7-f338-4f80-9a61-80df1212dba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 1\n",
      "Maximum review length: 2469\n"
     ]
    }
   ],
   "source": [
    "# Identifying the number of outliers\n",
    "review_lens = Counter([len(x) for x in reviews_int])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vntkyCqME1ph",
    "outputId": "57306555-4a88-4d12-85ff-935d6296e835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews before removing outliers:  50001\n",
      "Number of reviews after removing outliers:  50000\n"
     ]
    }
   ],
   "source": [
    "# Removing the Outliers\n",
    "print('Number of reviews before removing outliers: ', len(reviews_int))  \n",
    "non_zero_idx = [ii for ii, review in enumerate(reviews_int) if len(review) != 0]\n",
    "\n",
    "# Remove all the details about 0-length reviews \n",
    "reviews_int = [reviews_int[ii] for ii in non_zero_idx] \n",
    "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])  \n",
    "print('Number of reviews after removing outliers: ', len(reviews_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMbKpC0DE1rj",
    "outputId": "e7a2441f-1c2b-4b44-a7fe-82371e46b654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   28     4     1    77  1941    44  1063    11   100   145]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [81876 34938   110     7     1    59     4   291     6     3]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [   37   141    21     3   191   320     4 16021   163    18]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [   10    17    92     8    81    28     4    53   401   298]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [  100     1  1009     4   802   261     2    29  2223    29]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [   87     4    31   598    75     3   167   177   796   135]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    1  2637     6    33  4268   934     3 11682  1222    81]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [  310    17     6     3   362   538    11    44    74   223]]\n"
     ]
    }
   ],
   "source": [
    "# Making all reviews of same length\n",
    "def pad_features(reviews_int, seq_length):\n",
    "\n",
    "  features = np.zeros((len(reviews_int), seq_length), dtype=int)\n",
    "  for i, row in enumerate(reviews_int):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "  return features\n",
    "\n",
    "# Testing the implementation\n",
    "seq_length = 200\n",
    "features = pad_features(reviews_int, seq_length=seq_length)\n",
    "\n",
    "## Test statements\n",
    "assert len(features) == len(reviews_int), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0]) == seq_length, \"Each feature row should contain seq_length values.\"\n",
    "print(features[:30,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUUaz-bLaref"
   },
   "source": [
    "## Training, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smkkSQdXE1vG",
    "outputId": "5a217e5d-048a-4122-a1b5-548e318e2aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(40000, 200) \n",
      "Validation set: \t(5000, 200) \n",
      "Test set: \t\t(5000, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKvY56S8bt7e"
   },
   "source": [
    "### Dataloaders and batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IELqRUObE1Z4"
   },
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "batch_size = 50\n",
    "\n",
    "# Shuffling the training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbOLW49WE1Wv",
    "outputId": "560cd479-ddaf-47e5-b2d2-601a948f44ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 200])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ...,    13,   178,   981],\n",
      "        [    0,     0,     0,  ...,    31,     1,    98],\n",
      "        [    0,     0,     0,  ...,   266,     1,  1222],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,     2,   103,    11],\n",
      "        [    0,     0,     0,  ...,    37,   115,  3451],\n",
      "        [28980,   878,   122,  ...,    50,     8,  1999]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkJvIwzQb2qT"
   },
   "source": [
    "## Sentiment Network with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRtljcGvHpwS",
    "outputId": "14b9a107-0b2d-4a9b-aa9b-426016a16a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "  print('Training on GPU.')\n",
    "else:\n",
    "  print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CKJppRtjHpy2"
   },
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        # linear and sigmoid layers\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        sig_out = self.sig(out)\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]\n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lmM5EVJHp0f",
    "outputId": "d255c0a8-9dd7-4aaa-8bc4-192511c9c272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(182728, 512)\n",
      "  (lstm): LSTM(512, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the hyperparameters\n",
    "vocab_size = len(vocab_to_int)+1\n",
    "output_size = 1\n",
    "embedding_dim = 512\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)\n",
    "# Loss and optimization\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PZcipVVHp35",
    "outputId": "db747e82-d1ea-43a4-d9f9-d1c4a4ac2513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.750410... Val Loss: 0.746545\n",
      "Epoch: 1/4... Step: 200... Loss: 0.573088... Val Loss: 0.639460\n",
      "Epoch: 1/4... Step: 300... Loss: 0.691579... Val Loss: 0.692826\n",
      "Epoch: 1/4... Step: 400... Loss: 0.678167... Val Loss: 0.665632\n",
      "Epoch: 1/4... Step: 500... Loss: 0.670626... Val Loss: 0.587338\n",
      "Epoch: 1/4... Step: 600... Loss: 0.534300... Val Loss: 0.564771\n",
      "Epoch: 1/4... Step: 700... Loss: 0.421392... Val Loss: 0.510150\n",
      "Epoch: 1/4... Step: 800... Loss: 0.504427... Val Loss: 0.490066\n",
      "Epoch: 2/4... Step: 900... Loss: 0.404255... Val Loss: 0.427317\n",
      "Epoch: 2/4... Step: 1000... Loss: 0.322211... Val Loss: 0.400227\n",
      "Epoch: 2/4... Step: 1100... Loss: 0.221610... Val Loss: 0.402740\n",
      "Epoch: 2/4... Step: 1200... Loss: 0.290652... Val Loss: 0.365611\n",
      "Epoch: 2/4... Step: 1300... Loss: 0.202752... Val Loss: 0.374199\n",
      "Epoch: 2/4... Step: 1400... Loss: 0.274044... Val Loss: 0.351327\n",
      "Epoch: 2/4... Step: 1500... Loss: 0.299229... Val Loss: 0.363770\n",
      "Epoch: 2/4... Step: 1600... Loss: 0.282455... Val Loss: 0.320212\n",
      "Epoch: 3/4... Step: 1700... Loss: 0.106854... Val Loss: 0.388730\n",
      "Epoch: 3/4... Step: 1800... Loss: 0.260666... Val Loss: 0.356456\n",
      "Epoch: 3/4... Step: 1900... Loss: 0.104551... Val Loss: 0.370748\n",
      "Epoch: 3/4... Step: 2000... Loss: 0.085963... Val Loss: 0.371762\n",
      "Epoch: 3/4... Step: 2100... Loss: 0.209207... Val Loss: 0.363522\n",
      "Epoch: 3/4... Step: 2200... Loss: 0.241574... Val Loss: 0.338751\n",
      "Epoch: 3/4... Step: 2300... Loss: 0.145672... Val Loss: 0.355450\n",
      "Epoch: 3/4... Step: 2400... Loss: 0.240282... Val Loss: 0.342598\n",
      "Epoch: 4/4... Step: 2500... Loss: 0.130878... Val Loss: 0.432868\n",
      "Epoch: 4/4... Step: 2600... Loss: 0.091217... Val Loss: 0.443097\n",
      "Epoch: 4/4... Step: 2700... Loss: 0.316820... Val Loss: 0.463384\n",
      "Epoch: 4/4... Step: 2800... Loss: 0.157758... Val Loss: 0.437040\n",
      "Epoch: 4/4... Step: 2900... Loss: 0.093279... Val Loss: 0.428307\n",
      "Epoch: 4/4... Step: 3000... Loss: 0.072592... Val Loss: 0.433491\n",
      "Epoch: 4/4... Step: 3100... Loss: 0.050970... Val Loss: 0.435903\n",
      "Epoch: 4/4... Step: 3200... Loss: 0.090573... Val Loss: 0.418272\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 4\n",
    "counter = 0\n",
    "printing = 100\n",
    "batch_size = 50\n",
    "clip = 5 # Gradient clipping\n",
    "\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "for e in range(epochs):\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # Batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        h = tuple([each.data for each in h])\n",
    "        net.zero_grad()\n",
    "        output, h = net(inputs, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        if counter % printing == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JkzczMxHqAB",
    "outputId": "cb64cc8a-da5e-490f-a2a4-8d006227896b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.433\n",
      "Test accuracy: 0.858\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# Iterating over test data\n",
    "for inputs, labels in test_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    output, h = net(inputs, h)\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # Converting output probabilities to predicted class\n",
    "    pred = torch.round(output.squeeze())\n",
    "    # Comparing predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Testing the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ApMkVDGRHqCU"
   },
   "outputs": [],
   "source": [
    "review_neg = 'It is a film with a faulty assembly, as boring and exhausting as the predecessor.'\n",
    "review_pos = 'What you will be getting when you walk into an inevitably overstuffed movie theater is something singular that reflects our age in a way that none of the Marvel films that preceded it have - indeed, very few Hollywood spectacles ever have.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4TlWG-4HqFq",
    "outputId": "531f55af-ae9b-4585-ddd1-9699543bacc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 6, 3, 19, 15, 3, 14542, 12813, 14, 347, 2, 13049, 14, 1, 5618]]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_review(test_review):\n",
    "    test_review = test_review.lower()\n",
    "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
    "    test_words = test_text.split()\n",
    "    test_ints = []\n",
    "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
    "    return test_ints\n",
    "\n",
    "test_ints = tokenize_review(review_neg)\n",
    "print(test_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zZGO_Y8HpuB",
    "outputId": "60c57771-c5d4-4382-b551-b31617b5f4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     8     6     3    19    15     3 14542\n",
      "  12813    14   347     2 13049    14     1  5618]]\n"
     ]
    }
   ],
   "source": [
    "seq_length=200\n",
    "features = pad_features(test_ints, seq_length)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmIqvxJCRS29",
    "outputId": "89dbfc4f-0dc6-4ef9-f07f-1254d41e5100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "feature_tensor = torch.from_numpy(features)\n",
    "print(feature_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Ob1WQd3VRVO_"
   },
   "outputs": [],
   "source": [
    "def predict(net, test_review, sequence_length=200):\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "    # Tokenize \n",
    "    test_ints = tokenize_review(test_review)\n",
    "    # Pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "    \n",
    "    # Convert to tensor to pass into the model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    batch_size = feature_tensor.size(0)\n",
    "    # Initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    output, h = net(feature_tensor, h)\n",
    "    pred = torch.round(output.squeeze()) \n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    \n",
    "    # print custom response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Positive review detected:)\")\n",
    "    else:\n",
    "        print(\"Negative review detected:(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NiBeFltRcSn",
    "outputId": "ba49b43e-f7d1-471d-bce9-3cd5e9327a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.049122\n",
      "Negative review detected:(\n"
     ]
    }
   ],
   "source": [
    "seq_length = 200 \n",
    "predict(net, review_neg, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDDIGkA25c_i",
    "outputId": "7a92e5b1-42e2-405e-9e3a-a610d02ce3d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.918858\n",
      "Positive review detected:)\n"
     ]
    }
   ],
   "source": [
    "predict(net, review_pos, seq_length)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Medium_RNN_LSTM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
